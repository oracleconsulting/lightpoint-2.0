/**
 * Knowledge Base Document Upload Processor
 * 
 * Handles document text extraction and preparation for AI comparison
 * Note: Storage upload is now handled server-side via tRPC
 */

interface ProcessedDocument {
  filename: string;
  fileType: string;
  fileSize: number;
  extractedText: string;
  documentChunks: string[];
  fileBuffer: ArrayBuffer; // Send to server for storage upload
}

/**
 * Extract text from various file types
 */
async function extractTextFromFile(file: File): Promise<string> {
  const fileType = file.name.split('.').pop()?.toLowerCase();
  
  if (fileType === 'pdf') {
    // Use pdf-parse for PDFs
    const arrayBuffer = await file.arrayBuffer();
    const pdfParse = (await import('pdf-parse/lib/pdf-parse' as any)).default;
    const data = await pdfParse(Buffer.from(arrayBuffer));
    return data.text;
  } else if (fileType === 'txt') {
    // Plain text
    return await file.text();
  } else if (fileType === 'docx' || fileType === 'doc') {
    // Use mammoth for Word documents
    const arrayBuffer = await file.arrayBuffer();
    const mammoth = await import('mammoth');
    const result = await mammoth.extractRawText({ arrayBuffer });
    return result.value;
  } else if (fileType === 'xlsx' || fileType === 'xls' || fileType === 'csv') {
    // Use xlsx for Excel/CSV
    const arrayBuffer = await file.arrayBuffer();
    const XLSX = await import('xlsx');
    const workbook = XLSX.read(arrayBuffer, { type: 'array' });
    let text = '';
    workbook.SheetNames.forEach(sheetName => {
      const sheet = workbook.Sheets[sheetName];
      text += XLSX.utils.sheet_to_txt(sheet) + '\n\n';
    });
    return text;
  } else {
    throw new Error(`Unsupported file type: ${fileType}`);
  }
}

/**
 * Chunk text into smaller pieces for better embedding and comparison
 */
function chunkText(text: string, chunkSize: number = 1000): string[] {
  const chunks: string[] = [];
  const paragraphs = text.split(/\n\n+/);
  
  let currentChunk = '';
  
  for (const paragraph of paragraphs) {
    if (currentChunk.length + paragraph.length < chunkSize) {
      currentChunk += paragraph + '\n\n';
    } else {
      if (currentChunk) {
        chunks.push(currentChunk.trim());
      }
      currentChunk = paragraph + '\n\n';
    }
  }
  
  if (currentChunk) {
    chunks.push(currentChunk.trim());
  }
  
  return chunks.filter(chunk => chunk.length > 50); // Filter out tiny chunks
}

/**
 * Main function to process a document for KB upload
 */
export async function processDocumentForKB(
  file: File,
  orgId: string
): Promise<ProcessedDocument> {
  const startTime = Date.now();
  console.log(`üìÑ Processing ${file.name}...`);
  
  // 1. Read file buffer (will be uploaded server-side)
  console.log(`  ‚è≥ Step 1/3: Reading file buffer...`);
  const fileBuffer = await file.arrayBuffer();
  console.log(`  ‚úÖ Step 1/3: Read ${fileBuffer.byteLength} bytes (${Date.now() - startTime}ms)`);
  
  // 2. Extract text
  console.log(`  ‚è≥ Step 2/3: Extracting text from ${file.type || 'PDF'}...`);
  const extractStartTime = Date.now();
  const extractedText = await extractTextFromFile(file);
  console.log(`  ‚úÖ Step 2/3: Extracted ${extractedText.length} characters (${Date.now() - extractStartTime}ms)`);
  
  if (extractedText.length < 100) {
    throw new Error('Document appears to be empty or text extraction failed');
  }
  
  // 3. Chunk text
  console.log(`  ‚è≥ Step 3/3: Chunking text...`);
  const documentChunks = chunkText(extractedText);
  console.log(`  ‚úÖ Step 3/3: Created ${documentChunks.length} chunks (${Date.now() - startTime}ms total)`);
  
  return {
    filename: file.name,
    fileType: file.type || 'application/octet-stream',
    fileSize: file.size,
    extractedText,
    documentChunks,
    fileBuffer,
  };
}

/**
 * Process multiple documents in parallel
 */
export async function processMultipleDocuments(
  files: File[],
  orgId: string,
  onProgress?: (current: number, total: number, filename: string) => void
): Promise<ProcessedDocument[]> {
  const results: ProcessedDocument[] = [];
  
  for (let i = 0; i < files.length; i++) {
    const file = files[i];
    
    if (onProgress) {
      onProgress(i + 1, files.length, file.name);
    }
    
    try {
      const processed = await processDocumentForKB(file, orgId);
      results.push(processed);
    } catch (error: any) {
      console.error(`‚ùå Failed to process ${file.name}:`, error);
      // Continue with other files
    }
  }
  
  return results;
}

